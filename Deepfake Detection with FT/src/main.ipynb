{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from model import CombinedModel    \n",
    "from datasets import get_data_loaders, compute_mean_and_std\n",
    "from train import train\n",
    "# from test import evaluate, load_model\n",
    "\n",
    "# from tensorboard_utils import setup_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(learning_rate=0.001, checkpoint_dir='./checkpoints', log_dir='./logs', train_dir='D:/sp_cup/dataset/train', test_dir='D:/sp_cup/dataset//valid', batch_size=16, epochs=2)\n"
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training script')\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-3, help='Learning rate for the optimizer')\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='Directory to save checkpoints')\n",
    "    parser.add_argument('--log_dir', type=str, default='./logs', help='Directory for TensorBoard logs')\n",
    "    parser.add_argument('--train_dir', type=str, default='D:/sp_cup/dataset/train', help='Directory for training data')\n",
    "    parser.add_argument('--test_dir', type=str, default='D:/sp_cup/dataset//valid', help='Directory for testing data')\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='Batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=2, help='Number of epochs to train')\n",
    "    \n",
    "    # Use parse_known_args to avoid errors\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorBoard\n",
    "# writer = setup_tensorboard(args.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model\n",
      "CombinedModel(\n",
      "  (freq_branch): FrequencyBranch(\n",
      "    (fc1): Linear(in_features=98304, out_features=512, bias=True)\n",
      "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (conv_branch): ConvBranch(\n",
      "    (model): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (4): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (5): Flatten(start_dim=1, end_dim=-1)\n",
      "      (6): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing Model\")\n",
    "model = CombinedModel()\n",
    "\n",
    "\"\"\"model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_features = model.fc.in_features  # Get the number of features from the current fc layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 1), # Output layer for binary classification (Fake/Real)\n",
    "    nn.Sigmoid()\n",
    ")\"\"\"\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device: {device}\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "dataset_mean, dataset_std = compute_mean_and_std(args.train_dir)\n",
    "print(f\"Mean: {dataset_mean}, Std: {dataset_std}\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.3996, 0.3194, 0.3223], [0.2321, 0.1766, 0.1816])\n",
    "])\n",
    "train_loader, valid_loader = get_data_loaders(args.train_dir, args.test_dir, args.batch_size, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b23958cd7b417f969ff6a0b6447476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5d3cb82ca94fff98bbf6bffe61aa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Epoch [1/2], Batch [1/192], Loss: 0.7393\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Epoch [1/2], Batch [51/192], Loss: 0.7146\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n",
      "Output vector shape: torch.Size([16, 128])\n",
      "Frequency branch output: torch.Size([16, 128])\n",
      "Conv branch output: torch.Size([16, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart Training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\SP Cup\\Deepfake-Face-Detection-In-The-Wild\\Deepfake Detection with FT\\src\\train.py:22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, num_epochs, checkpoint_dir)\u001b[0m\n\u001b[0;32m     19\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     20\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 22\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Projects\\SP Cup\\Deepfake-Face-Detection-In-The-Wild\\Deepfake Detection with FT\\src\\datasets.py:21\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 21\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\skimage\\_shared\\utils.py:328\u001b[0m, in \u001b[0;36mdeprecate_parameter.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# Assign old value to new one\u001b[39;00m\n\u001b[0;32m    326\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_name] \u001b[38;5;241m=\u001b[39m deprecated_value\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\skimage\\io\\_io.py:82\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     79\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname, _hide_plugin_deprecation_warnings():\n\u001b[1;32m---> 82\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\skimage\\_shared\\utils.py:538\u001b[0m, in \u001b[0;36mdeprecate_func.__call__.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m stacklevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_stack_length(func) \u001b[38;5;241m-\u001b[39m stack_rank\n\u001b[0;32m    537\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(message, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel)\n\u001b[1;32m--> 538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\skimage\\io\\manage_plugins.py:254\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\imageio\\v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\imageio\\core\\imopen.py:196\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     plugin_instance \u001b[38;5;241m=\u001b[39m \u001b[43mcandidate_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InitializationError:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# file extension doesn't match file type\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\imageio\\plugins\\pillow.py:104\u001b[0m, in \u001b[0;36mPillowPlugin.__init__\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mio_mode \u001b[38;5;241m==\u001b[39m IOMode\u001b[38;5;241m.\u001b[39mread:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;66;03m# Check if it is generally possible to read the image.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;66;03m# This will not read any data and merely try to find a\u001b[39;00m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;66;03m# compatible pillow plugin (ref: the pillow docs).\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnidentifiedImageError:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\PIL\\Image.py:3442\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3439\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m   3440\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 3442\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3444\u001b[0m preinit()\n\u001b[0;32m   3446\u001b[0m warning_messages: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Start Training\")\n",
    "train(model, train_loader, criterion, optimizer, args.epochs, args.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Modify the fully connected layer to match the saved model\n",
    "num_features = loaded_model.fc.in_features\n",
    "loaded_model.fc = nn.Sequential(\n",
    "\tnn.Linear(num_features, 512),\n",
    "\tnn.ReLU(),\n",
    "\tnn.Dropout(0.5),\n",
    "\tnn.Linear(512, 1),\n",
    "\tnn.Sigmoid()\n",
    ")\n",
    "\n",
    "MODEL_SAVE_PATH = args.checkpoint_dir + '/final_checkpoint.pth'\n",
    "state_dict = torch.load(MODEL_SAVE_PATH)\n",
    "\n",
    "loaded_model.load_state_dict(state_dict)\n",
    "loaded_model = loaded_model.to(device)\n",
    "print(f\"Model loaded from {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set both models to evaluation mode\n",
    "model.eval()\n",
    "loaded_model.eval()\n",
    "\n",
    "# Compare the state dictionaries\n",
    "def compare_models(model1, model2):\n",
    "    model1_dict = model1.state_dict()\n",
    "    model2_dict = model2.state_dict()\n",
    "    \n",
    "    for key in model1_dict:\n",
    "        if not torch.equal(model1_dict[key], model2_dict[key]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Check if the parameters are identical\n",
    "are_identical = compare_models(model, loaded_model)\n",
    "print(f\"Are the trained model and loaded model parameters identical? {are_identical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_path = os.path.join(args.checkpoint_dir, 'final_checkpoint.pth')\n",
    "#print(f\"Loading model from {checkpoint_path}\")\n",
    "#model = load_model(checkpoint_path, model)\n",
    "\n",
    "evaluate(loaded_model, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
