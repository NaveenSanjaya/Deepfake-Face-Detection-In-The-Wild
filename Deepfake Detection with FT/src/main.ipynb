{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from models import Model\n",
    "from datasets import get_data_loaders\n",
    "from train import train\n",
    "from test import evaluate, load_model\n",
    "from pathlib import Path\n",
    "# from tensorboard_utils import setup_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(learning_rate=0.001, checkpoint_dir='./checkpoints', log_dir='./logs', train_dir='D:/sp_cup/dataset/valid', test_dir='D:/sp_cup/dataset/valid', batch_size=16, epochs=20)\n"
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training script')\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-3, help='Learning rate for the optimizer')\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='Directory to save checkpoints')\n",
    "    parser.add_argument('--log_dir', type=str, default='./logs', help='Directory for TensorBoard logs')\n",
    "    parser.add_argument('--train_dir', type=str, default='D:/sp_cup/dataset/valid', help='Directory for training data')\n",
    "    parser.add_argument('--test_dir', type=str, default='D:/sp_cup/dataset/valid', help='Directory for testing data')\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='Batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=20, help='Number of epochs to train')\n",
    "    \n",
    "    # Use parse_known_args to avoid errors\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorBoard\n",
    "# writer = setup_tensorboard(args.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing Model\")\n",
    "\n",
    "#model = Model()\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_features = model.fc.in_features  # Get the number of features from the current fc layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 1), # Output layer for binary classification (Fake/Real)\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device: {device}\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize([0.3996, 0.3194, 0.3223], [0.2321, 0.1766, 0.1816])\n",
    "])\n",
    "train_loader, valid_loader = get_data_loaders(args.train_dir, args.test_dir, args.batch_size, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8331f2cf92924b0d881653e308f28bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23657922b335493da26815e6bcfd1e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Batch [1/192], Loss: 0.6974\n",
      "Epoch [1/20], Batch [51/192], Loss: 0.2284\n",
      "Epoch [1/20], Batch [101/192], Loss: 0.0915\n",
      "Epoch [1/20], Batch [151/192], Loss: 0.0430\n",
      "Epoch [1/20], Loss: 0.1259, Accuracy: 94.99%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519013283e054a2daae4b0a5fc56e121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Batch [1/192], Loss: 0.0290\n",
      "Epoch [2/20], Batch [51/192], Loss: 0.0541\n",
      "Epoch [2/20], Batch [101/192], Loss: 0.0355\n",
      "Epoch [2/20], Batch [151/192], Loss: 0.0599\n",
      "Epoch [2/20], Loss: 0.0580, Accuracy: 97.53%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857515457d804d7e89ee576679efafa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Batch [1/192], Loss: 0.0206\n",
      "Epoch [3/20], Batch [51/192], Loss: 0.0001\n",
      "Epoch [3/20], Batch [101/192], Loss: 0.0001\n",
      "Epoch [3/20], Batch [151/192], Loss: 0.0936\n",
      "Epoch [3/20], Loss: 0.0655, Accuracy: 97.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995cbbc3584541d1960f530bd9fd8fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Batch [1/192], Loss: 0.1076\n",
      "Epoch [4/20], Batch [51/192], Loss: 0.0397\n",
      "Epoch [4/20], Batch [101/192], Loss: 0.0009\n",
      "Epoch [4/20], Batch [151/192], Loss: 0.0971\n",
      "Epoch [4/20], Loss: 0.0796, Accuracy: 96.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734ae365fe9d443ca664f58d195fa236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Batch [1/192], Loss: 0.0119\n",
      "Epoch [5/20], Batch [51/192], Loss: 0.0006\n",
      "Epoch [5/20], Batch [101/192], Loss: 0.0322\n",
      "Epoch [5/20], Batch [151/192], Loss: 0.0010\n",
      "Epoch [5/20], Loss: 0.0609, Accuracy: 97.33%\n",
      "Checkpoint saved at ./checkpoints\\checkpoint_epoch_5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a05070d242549239fc6415072c26f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Batch [1/192], Loss: 0.0001\n",
      "Epoch [6/20], Batch [51/192], Loss: 0.0498\n",
      "Epoch [6/20], Batch [101/192], Loss: 0.0057\n",
      "Epoch [6/20], Batch [151/192], Loss: 0.0300\n",
      "Epoch [6/20], Loss: 0.0395, Accuracy: 97.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a095ebbe023946bf8d3e5e926d1e3e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Batch [1/192], Loss: 0.0499\n",
      "Epoch [7/20], Batch [51/192], Loss: 0.0005\n",
      "Epoch [7/20], Batch [101/192], Loss: 0.0007\n",
      "Epoch [7/20], Batch [151/192], Loss: 0.0000\n",
      "Epoch [7/20], Loss: 0.0339, Accuracy: 97.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af7218d82674dfab31e2a3138860dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Batch [1/192], Loss: 0.0971\n",
      "Epoch [8/20], Batch [51/192], Loss: 0.0017\n",
      "Epoch [8/20], Batch [101/192], Loss: 0.0002\n",
      "Epoch [8/20], Batch [151/192], Loss: 0.0463\n",
      "Epoch [8/20], Loss: 0.0346, Accuracy: 97.92%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1858b5247d9a4f78abb9df705c77b77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Batch [1/192], Loss: 0.0491\n",
      "Epoch [9/20], Batch [51/192], Loss: 0.2336\n",
      "Epoch [9/20], Batch [101/192], Loss: 0.0292\n",
      "Epoch [9/20], Batch [151/192], Loss: 0.1633\n",
      "Epoch [9/20], Loss: 0.1136, Accuracy: 97.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2683d936cd5741c4a9297e659b022f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Batch [1/192], Loss: 0.0001\n",
      "Epoch [10/20], Batch [51/192], Loss: 0.2738\n",
      "Epoch [10/20], Batch [101/192], Loss: 0.0912\n",
      "Epoch [10/20], Batch [151/192], Loss: 0.0380\n",
      "Epoch [10/20], Loss: 0.0520, Accuracy: 97.33%\n",
      "Checkpoint saved at ./checkpoints\\checkpoint_epoch_10.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b3e374f49c44fc8e7443274c8dc379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Batch [1/192], Loss: 0.0511\n",
      "Epoch [11/20], Batch [51/192], Loss: 0.0002\n",
      "Epoch [11/20], Batch [101/192], Loss: 0.0421\n",
      "Epoch [11/20], Batch [151/192], Loss: 0.0383\n",
      "Epoch [11/20], Loss: 0.0379, Accuracy: 97.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a92b8fa81b54eb7b59a74a2d2936fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Batch [1/192], Loss: 0.0044\n",
      "Epoch [12/20], Batch [51/192], Loss: 0.0403\n",
      "Epoch [12/20], Batch [101/192], Loss: 0.0363\n",
      "Epoch [12/20], Batch [151/192], Loss: 0.0018\n",
      "Epoch [12/20], Loss: 0.0422, Accuracy: 97.66%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd9f9361fdf477892e19d35080bb164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Batch [1/192], Loss: 0.1618\n",
      "Epoch [13/20], Batch [51/192], Loss: 0.0007\n",
      "Epoch [13/20], Batch [101/192], Loss: 0.0264\n",
      "Epoch [13/20], Batch [151/192], Loss: 0.0208\n",
      "Epoch [13/20], Loss: 0.0501, Accuracy: 97.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8262464523b340cbbe6f6e5de08812e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Batch [1/192], Loss: 0.0391\n",
      "Epoch [14/20], Batch [51/192], Loss: 0.1288\n",
      "Epoch [14/20], Batch [101/192], Loss: 0.0001\n",
      "Epoch [14/20], Batch [151/192], Loss: 0.0002\n",
      "Epoch [14/20], Loss: 0.0515, Accuracy: 97.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d803e979904904a7631df8ca6e4b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Batch [1/192], Loss: 0.0302\n",
      "Epoch [15/20], Batch [51/192], Loss: 0.0000\n",
      "Epoch [15/20], Batch [101/192], Loss: 0.0111\n",
      "Epoch [15/20], Batch [151/192], Loss: 0.1617\n",
      "Epoch [15/20], Loss: 0.0422, Accuracy: 97.59%\n",
      "Checkpoint saved at ./checkpoints\\checkpoint_epoch_15.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdf8524cfb147b09962868eb0cb5934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Batch [1/192], Loss: 0.1003\n",
      "Epoch [16/20], Batch [51/192], Loss: 0.0534\n",
      "Epoch [16/20], Batch [101/192], Loss: 0.0449\n",
      "Epoch [16/20], Batch [151/192], Loss: 0.0000\n",
      "Epoch [16/20], Loss: 0.0333, Accuracy: 97.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341c6536d4fa4aecabfc6cb52ae61fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Batch [1/192], Loss: 0.0447\n",
      "Epoch [17/20], Batch [51/192], Loss: 0.0000\n",
      "Epoch [17/20], Batch [101/192], Loss: 0.0000\n",
      "Epoch [17/20], Batch [151/192], Loss: 0.0429\n",
      "Epoch [17/20], Loss: 0.0327, Accuracy: 97.88%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08976ff5cbb427c8f49f88e8903e309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Batch [1/192], Loss: 0.0001\n",
      "Epoch [18/20], Batch [51/192], Loss: 0.0424\n",
      "Epoch [18/20], Batch [101/192], Loss: 0.0000\n",
      "Epoch [18/20], Batch [151/192], Loss: 0.0001\n",
      "Epoch [18/20], Loss: 0.0327, Accuracy: 97.92%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa56f75314f4ff5948284a5a5521aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Batch [1/192], Loss: 0.0029\n",
      "Epoch [19/20], Batch [51/192], Loss: 0.0352\n",
      "Epoch [19/20], Batch [101/192], Loss: 0.0018\n",
      "Epoch [19/20], Batch [151/192], Loss: 0.0408\n",
      "Epoch [19/20], Loss: 0.0351, Accuracy: 97.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d54ee57c0a7471a9b522bc313da2fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Batch [1/192], Loss: 0.0013\n",
      "Epoch [20/20], Batch [51/192], Loss: 0.1592\n",
      "Epoch [20/20], Batch [101/192], Loss: 0.0214\n",
      "Epoch [20/20], Batch [151/192], Loss: 0.0164\n",
      "Epoch [20/20], Loss: 0.0823, Accuracy: 97.27%\n",
      "Checkpoint saved at ./checkpoints\\checkpoint_epoch_20.pth\n",
      "Saving model to: models\\model_01_resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Start Training\")\n",
    "train(model, train_loader, criterion, optimizer, args.epochs, args.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/model_01_resnet50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VICTUS\\AppData\\Local\\Temp\\ipykernel_10332\\1059343257.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_SAVE_PATH)\n"
     ]
    }
   ],
   "source": [
    "loaded_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Modify the fully connected layer to match the saved model\n",
    "num_features = loaded_model.fc.in_features\n",
    "loaded_model.fc = nn.Sequential(\n",
    "\tnn.Linear(num_features, 512),\n",
    "\tnn.ReLU(),\n",
    "\tnn.Dropout(0.5),\n",
    "\tnn.Linear(512, 1),\n",
    "\tnn.Sigmoid()\n",
    ")\n",
    "\n",
    "MODEL_SAVE_PATH = 'models/model_01_resnet50.pth'\n",
    "state_dict = torch.load(MODEL_SAVE_PATH)\n",
    "\n",
    "loaded_model.load_state_dict(state_dict)\n",
    "loaded_model = loaded_model.to(device)\n",
    "print(f\"Model loaded from {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the trained model and loaded model parameters identical? True\n"
     ]
    }
   ],
   "source": [
    "# Set both models to evaluation mode\n",
    "model.eval()\n",
    "loaded_model.eval()\n",
    "\n",
    "# Compare the state dictionaries\n",
    "def compare_models(model1, model2):\n",
    "    model1_dict = model1.state_dict()\n",
    "    model2_dict = model2.state_dict()\n",
    "    \n",
    "    for key in model1_dict:\n",
    "        if not torch.equal(model1_dict[key], model2_dict[key]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Check if the parameters are identical\n",
    "are_identical = compare_models(model, loaded_model)\n",
    "print(f\"Are the trained model and loaded model parameters identical? {are_identical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 49.61%\n",
      "True Negatives (Real identified as Real): 1524\n",
      "False Positives (Real identified as Fake): 0\n",
      "False Negatives (Fake identified as Real): 1548\n",
      "True Positives (Fake identified as Fake): 0\n",
      "Confusion Matrix:\n",
      "[[1524    0]\n",
      " [1548    0]]\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = os.path.join(args.checkpoint_dir, 'final_checkpoint.pth')\n",
    "#print(f\"Loading model from {checkpoint_path}\")\n",
    "#model = load_model(checkpoint_path, model)\n",
    "\n",
    "evaluate(loaded_model, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
