{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Check versions\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to real and fake image directories\n",
    "train_real_path = r\"D:\\Projects\\SP CUP Dataset\\train\\real\" # r is because of the backslash causing \\p \n",
    "train_fake_path = r\"D:\\Projects\\SP CUP Dataset\\train\\fake\" # to be interpreted as a special character\n",
    "\n",
    "test_real_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\real\"\n",
    "test_fake_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\fake\"\n",
    "\n",
    "#Small Dataset\n",
    "#train_real_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\real\" # r is because of the backslash causing \\p \n",
    "#train_fake_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\fake\" # to be interpreted as a special character\n",
    "\n",
    "#test_real_path = r\"D:\\Projects\\SP CUP Dataset\\Small train\\real\"\n",
    "#test_fake_path = r\"D:\\Projects\\SP CUP Dataset\\Small train\\fake\"\n",
    "#r\"D:\\Projects\\SP CUP Dataset\\Small train\\real\"\n",
    "#r\"D:\\Projects\\SP CUP Dataset\\Small train\\fake\"\n",
    "\n",
    "#Define the maximum number of samples per class\n",
    "TRAIN_MAX_SAMPLES_PER_CLASS = 40000  # Programmer-defined limit\n",
    "TEST_MAX_SAMPLES_PER_CLASS = 40000  # Programmer-defined limit\n",
    "\n",
    "BATCH_SIZE = 16 # Batch size for training\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✔ 0 for real and 1 for fake since classes = ['real', 'fake']\n",
    "\n",
    "✔ The train_dataloader is created with shuffle=True to shuffle the training data at the beginning of each epoch. (not implemented )\n",
    "\n",
    "✔ The test_dataloader is created with shuffle=False to keep the order of the test data consistent.\n",
    "\n",
    "✔Read efficientnet documentation and act accordingly\n",
    "\n",
    "Way to save the model using checkpoints.\n",
    "\n",
    "Way to get std and mean of the provided dataset\n",
    "\n",
    "Apply regularization (Model markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Set dataset folders for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image filenames\n",
    "train_real_count = len(os.listdir(train_real_path))\n",
    "train_fake_count = len(os.listdir(train_fake_path))\n",
    "\n",
    "test_real_count = len(os.listdir(test_real_path))\n",
    "test_fake_count = len(os.listdir(test_fake_path))\n",
    "\n",
    "print(f\"Train Real images: {train_real_count}, Train Fake images: {train_fake_count}\")\n",
    "print(f\"Test Real images: {test_real_count}, Test Fake images: {test_fake_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "#Define the maximum number of samples per class\n",
    "MAX_SAMPLES_PER_CLASS = 40000  # Programmer-defined limit\n",
    "\n",
    "# Get the image filenames\n",
    "train_real_images = os.listdir(train_real_path)\n",
    "train_fake_images = os.listdir(train_fake_path)\n",
    "\n",
    "# Apply the limit\n",
    "train_real_images = train_real_images[:min(MAX_SAMPLES_PER_CLASS, len(train_real_images))]\n",
    "train_fake_images = train_fake_images[:min(MAX_SAMPLES_PER_CLASS, len(train_fake_images))]\n",
    "\n",
    "# Combine and label the dataset\n",
    "train_balanced_dataset = [(os.path.join(train_real_path, img), 0) for img in train_real_images] + \\\n",
    "                   [(os.path.join(train_fake_path, img), 1) for img in train_fake_images]\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(train_balanced_dataset)\n",
    "\n",
    "# Verify the limited dataset size\n",
    "print(f\"Total dataset size: {len(train_balanced_dataset)} (Real: {len(train_real_images)}, Fake: {len(train_fake_images)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Preparing Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "#Define the maximum number of samples per class\n",
    "MAX_SAMPLES_PER_CLASS = 40000  # Programmer-defined limit\n",
    "\n",
    "# Get the image filenames\n",
    "test_real_images = os.listdir(test_real_path)\n",
    "test_fake_images = os.listdir(test_fake_path)\n",
    "\n",
    "# Apply the limit\n",
    "test_real_images = test_real_images[:min(MAX_SAMPLES_PER_CLASS, len(test_real_images))]\n",
    "test_fake_images = test_fake_images[:min(MAX_SAMPLES_PER_CLASS, len(test_fake_images))]\n",
    "\n",
    "# Combine and label the dataset\n",
    "# test_balanced_dataset[0] = ('D:\\\\Projects\\\\SP CUP Dataset\\\\valid\\\\fake\\\\valid_fake_0228446.png', 1)\n",
    "test_balanced_dataset = [(os.path.join(test_real_path, img), 0) for img in test_real_images] + \\\n",
    "                   [(os.path.join(test_fake_path, img), 1) for img in test_fake_images]\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(test_balanced_dataset)\n",
    "\n",
    "# Verify the limited dataset size\n",
    "print(f\"Total dataset size: {len(test_balanced_dataset)} (Real: {len(test_real_images)}, Fake: {len(test_fake_images)})\")\n",
    "#type(test_balanced_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first image from the balanced dataset\n",
    "image_path, label = train_balanced_dataset[0]\n",
    "image_path, label = test_balanced_dataset[0]\n",
    "\n",
    "# Open the image using PIL\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.figure(figsize=(2, 2))  # Adjust the figsize to make the image smaller\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Label: {'Real' if label == 0 else 'Fake'}\")\n",
    "plt.xlabel(os.path.basename(image_path))  # Display the image name\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()\n",
    "\n",
    "# Display the image file name after the image\n",
    "print(f\"Image file name: {os.path.basename(image_path)}\")\n",
    "print(f\"Image Shape: {image.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Plot more Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Randomly select 5 images from the balanced dataset\n",
    "#selected_indices = random.sample(range(len(train_balanced_dataset)), 5)\n",
    "#balanced_dataset5_1 = train_balanced_dataset\n",
    "selected_indices = random.sample(range(len(test_balanced_dataset)), 5)\n",
    "balanced_dataset5_1 = test_balanced_dataset\n",
    "\n",
    "\n",
    "# Display 5 images in a row\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))  # 1 row, 5 columns\n",
    "\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    image_path, label = balanced_dataset5_1[idx]\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"Label: {'Real' if label == 0 else 'Fake'}\")\n",
    "    axes[i].set_xlabel(os.path.basename(image_path))  # Display the image name\n",
    "    axes[i].axis('off')  # Hide the axis\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display the image file names after the images\n",
    "for idx in selected_indices:\n",
    "    image_path, _ = balanced_dataset5_1[idx]\n",
    "    print(f\"Image file name: {os.path.basename(image_path)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Getting the datasets ( Setup training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Finding out mean and std to use in the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Step 1: Define a custom dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        super().__init__()  # Call the parent class's init method\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        #return image, label, img_path\n",
    "        return image, label\n",
    "    \n",
    "# Step 2: Define basic transform (only ToTensor) for statistics calculation\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Converts image to tensor without altering pixel values\n",
    "])\n",
    "\n",
    "# Step 3: Create custom datasets for training and testing\n",
    "#Already created test_balanced_dataset and train_balanced_dataset\n",
    "\n",
    "train_dataset_raw = ImageDataset(train_balanced_dataset, transform=basic_transform)\n",
    "test_dataset_raw = ImageDataset(test_balanced_dataset, transform=basic_transform)\n",
    "\n",
    "# Step 4: Create dataloaders for raw datasets\n",
    "train_dataloader_raw = DataLoader(train_dataset_raw, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_dataloader_raw = DataLoader(test_dataset_raw, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# Step 5: Function to calculate mean and std\n",
    "def compute_mean_std(loader):\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)  # Batch size\n",
    "        images = images.view(batch_samples, images.size(1), -1)  # Reshape to (B, C, H*W)\n",
    "        mean += images.mean(2).sum(0)  # Sum of means for each channel\n",
    "        std += images.std(2).sum(0)  # Sum of std for each channel\n",
    "        n_samples += batch_samples\n",
    "\n",
    "    mean /= n_samples\n",
    "    std /= n_samples\n",
    "    return mean, std\n",
    "\n",
    "# Step 6: Compute mean and std for training and testing datasets\n",
    "train_mean, train_std = compute_mean_std(train_loader_raw)\n",
    "test_mean, test_std = compute_mean_std(test_loader_raw)\n",
    "\n",
    "print(f\"Training Dataset Mean: {train_mean}, Std: {train_std}\")\n",
    "print(f\"Testing Dataset Mean: {test_mean}, Std: {test_std}\")\n",
    "\n",
    "# Step 7: Define normalization transforms using computed mean and std\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean.tolist(), std=train_std.tolist())\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=test_mean.tolist(), std=test_std.tolist())\n",
    "])\n",
    "\n",
    "# Step 8: Reload datasets with normalization transforms\n",
    "train_dataset = CustomImageDataset(train_dataset, transform=train_transform)\n",
    "test_dataset = CustomImageDataset(test_dataset, transform=test_transform)\n",
    "\n",
    "# Step 9: Create dataloaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# Now you can use train_loader and test_loader for training and testing your model\n",
    "test_dataloader = DataLoader(test_data, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        super().__init__()  # Call the parent class's init method\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        #return image, label, img_path\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),  # First resize to 256\n",
    "    transforms.CenterCrop(224),  # Then center crop to 224\n",
    "    transforms.ToTensor(),  # Converts to tensor and scales to [0.0, 1.0]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Define the classes\n",
    "classes = ['real', 'fake']\n",
    "\n",
    "#Create the dataset\n",
    "train_dataset = ImageDataset(train_balanced_dataset, \n",
    "                          transform=transform)\n",
    "\n",
    "#Create the dataset\n",
    "test_dataset = ImageDataset(test_balanced_dataset, \n",
    "                        transform=transform)\n",
    "\n",
    "# Example: Print the class name of a label\n",
    "for image, label in test_dataset:\n",
    "    class_name = classes[label]\n",
    "    print(f\"Image Shape {image.shape}, Image label: {label}, Class name: {class_name}\")\n",
    "    break  # Just print the first one for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Visualize train_dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "# Randomly select 5 images from the balanced dataset\n",
    "selected_indices = random.sample(range(len(train_balanced_dataset)), 5)\n",
    "\n",
    "# Display 5 images before and after transform\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))  # 2 rows, 5 columns\n",
    "\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    image_path, label = train_balanced_dataset[idx]\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Display original image\n",
    "    axes[0, i].imshow(image)\n",
    "    axes[0, i].set_title(f\"Original\\nLabel: {'Real' if label == 0 else 'Fake'}\")\n",
    "    axes[0, i].axis('off')  # Hide the axis\n",
    "\n",
    "    # Apply transform and display transformed image\n",
    "    transformed_image = transform(image)\n",
    "    axes[1, i].imshow(transformed_image.permute(1, 2, 0) * 0.5 + 0.5)  # Unnormalize the image\n",
    "    axes[1, i].set_title(f\"Transformed\\nLabel: {'Real' if label == 0 else 'Fake'}\")\n",
    "    axes[1, i].axis('off')  # Hide the axis\n",
    "\n",
    "    print(f\"Image Name: {image_path}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset)) \n",
    "print(len(test_dataset))\n",
    "\n",
    "#image, label = train_data[700] # Label is 1\n",
    "image, label = train_dataset[1600] # Label is 0\n",
    "print(image.shape, label)\n",
    "\n",
    "# Check the shape of our image\n",
    "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image label: {[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Checking Labels of more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "#dataset = train_dataset\n",
    "dataset = test_dataset\n",
    "\n",
    "\n",
    "# Select 50 random images\n",
    "selected_indices = random.sample(range(len(dataset)), 10)\n",
    "\n",
    "# Print the shape of images and labels of 50 random images\n",
    "for idx in selected_indices:\n",
    "    image, label = dataset[idx]\n",
    "    image_path, _ = dataset.data[idx]\n",
    "    print(f\"Image file name: {os.path.basename(image_path)}\")\n",
    "    print(f\"Image shape: {image.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Visualize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Randomly select 5 images from the train_dataset dataset\n",
    "selected_indices = random.sample(range(len(train_data)), 5)\n",
    "\n",
    "# Display 5 images in a row\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))  # 1 row, 5 columns\n",
    "\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    image, label = train_data[idx]\n",
    "    image = image.permute(1, 2, 0) * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])  # Unnormalize the image\n",
    "    \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"Label: {'Real' if label == 0 else 'Fake'}\")\n",
    "    axes[i].axis('off')  # Hide the axis\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display the image file names after the images\n",
    "for idx in selected_indices:\n",
    "    image_path, _ = train_data.data[idx]\n",
    "    print(f\"Image file name: {os.path.basename(image_path)}\")\n",
    "\n",
    "#These images are from the dataset after appplying the transformation ao the image is cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Visualize more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "#balanced_dataset7_3 = train_balanced_dataset\n",
    "balanced_dataset7_3 = test_balanced_dataset\n",
    "\n",
    "# Randomly select 9 images from the balanced dataset\n",
    "selected_indices = random.sample(range(len(balanced_dataset7_3)), 9)\n",
    "\n",
    "# Display 9 images in a 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))  # 3 rows, 3 columns\n",
    "\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    image_path, label = balanced_dataset7_3[idx]\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f\"Label: {'Real' if label == 0 else 'Fake'}\")\n",
    "    ax.set_xlabel(os.path.basename(image_path))  # Display the image name\n",
    "    ax.axis('off')  # Hide the axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the image file names after the images\n",
    "for idx in selected_indices:\n",
    "    image_path, _ = balanced_dataset7_3[idx]\n",
    "    print(f\"Image file name: {os.path.basename(image_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Prepare DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False)\n",
    "\n",
    "# Example: Iterate through the DataLoader\n",
    "for images, labels in test_dataloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break\n",
    "\n",
    "print(images[0].shape)\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 Check what we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out what what we've created\n",
    "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}... = {BATCH_SIZE*len(train_dataloader)}\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}... = {BATCH_SIZE*len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 What's inside the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Building a baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x) # perform forward pass\n",
    "\n",
    "# Print out what happened\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 Modelv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch import nn\n",
    "#class DeepFakeDetectV0(nn.Module):\n",
    "#  def __init__(self,\n",
    "#               input_shape: int,\n",
    "#               hidden_units: int,\n",
    "#               output_shape: int):\n",
    "#    super().__init__()\n",
    "#    self.layer_stack = nn.Sequential(\n",
    "#        nn.Flatten(),\n",
    "#        nn.Linear(in_features=input_shape,\n",
    "#                  out_features=hidden_units),\n",
    "#        nn.Linear(in_features=hidden_units,\n",
    "#                  out_features=output_shape)\n",
    "#    )\n",
    "#\n",
    "#  def forward(self, x):\n",
    "#    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to use efficientnet_b3 or efficientnet_b7\n",
    "\n",
    "# Load pre-trained EfficientNet model\n",
    "class DeepFakeDetectV0(nn.Module):\n",
    "    def __init__(self, output_shape: int):\n",
    "        super(DeepFakeDetectV0, self).__init__()\n",
    "        # Load pre-trained EfficientNet model\n",
    "        self.efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        \n",
    "        # Unfreeze more layers\n",
    "        for param in self.efficientnet.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(num_ftrs, output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization is a technique used in machine learning and deep learning to prevent overfitting, which occurs when a model learns the training data too well, including its noise and outliers, and performs poorly on new, unseen data. Regularization techniques add constraints or penalties to the model to encourage it to generalize better to new data.\n",
    "\n",
    "Here are some common regularization techniques:\n",
    "\n",
    "L1 and L2 Regularization:\n",
    "\n",
    "L1 Regularization (Lasso): Adds the absolute value of the coefficients as a penalty term to the loss function. It can lead to sparse models where some feature weights are exactly zero, effectively performing feature selection.\n",
    "L2 Regularization (Ridge): Adds the squared value of the coefficients as a penalty term to the loss function. It helps in reducing the magnitude of the coefficients but does not lead to sparsity.\n",
    "Example in PyTorch:\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
    "\n",
    "Dropout:\n",
    "\n",
    "Dropout is a technique where randomly selected neurons are ignored during training. This prevents the model from becoming too reliant on specific neurons and encourages it to learn more robust features.\n",
    "Example in PyTorch:\n",
    "\n",
    "self.efficientnet.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5, inplace=True),  # Dropout with a probability of 0.5\n",
    "    nn.Linear(num_ftrs, output_shape)\n",
    ")\n",
    "\n",
    "Data Augmentation:\n",
    "\n",
    "Data augmentation involves creating new training samples by applying random transformations (e.g., rotations, flips, crops) to the existing data. This increases the diversity of the training data and helps the model generalize better.\n",
    "Example in PyTorch:\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "Early Stopping:\n",
    "\n",
    "Early stopping involves monitoring the model's performance on a validation set and stopping the training process when the performance stops improving. This prevents the model from overfitting the training data.\n",
    "Example:\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training code...\n",
    "    val_loss = evaluate(model, val_dataloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "Batch Normalization:\n",
    "\n",
    "Batch normalization normalizes the inputs of each layer to have a mean of zero and a standard deviation of one. This helps in stabilizing and accelerating the training process.\n",
    "Example in PyTorch:\n",
    "\n",
    "self.efficientnet.features.add_module(\"batch_norm\", nn.BatchNorm2d(num_features))\n",
    "\n",
    "By incorporating these regularization techniques, you can improve the generalization ability of your model and reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2 Setup the model for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = DeepFakeDetectV0(output_shape=1)\n",
    "model_0.to(device)\n",
    "\n",
    "# Check the device of the model\n",
    "model_0_device = next(model_0.parameters()).device\n",
    "print(f\"Model is on device: {model_0_device}\")\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model with input parameters\n",
    "#model_0 = DeepFakeDetectV0(\n",
    "#    input_shape=3*224*224, # this is 128*128 (height*width)\n",
    "#    hidden_units=10, # how mnay units in the hidden layer\n",
    "#    output_shape=1 # one for every class\n",
    "#).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.3 Send a random value through to check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with random tensor (batch_size=32, channels=3, height=224, width=224)\n",
    "test_input = torch.randn(32, 3, 224, 224).to(device)\n",
    "output = model_0(test_input)\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Sample predictions:\\n{output[:5].cpu().detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x = torch.rand([1, 3, 224, 224]).to(device)\n",
    "model_0(dummy_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.4 Check the State Dictionary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Setup Loss, Optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1 Setup Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            #lr=0.01)\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model_0.parameters(), lr=0.01)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "#scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2 Function to time our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "  \"\"\"Prints difference between start and end time.\"\"\"\n",
    "  total_time = end - start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time\n",
    "\n",
    "start_time = timer()\n",
    "# some code...\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the test_dataloader and print the first 5 values\n",
    "for i, (images, labels) in enumerate(test_dataloader):\n",
    "    if i < 1:\n",
    "        print(f\"Batch {i+1}:\")\n",
    "        print(f\"Images: {images}\")\n",
    "        print(f\"Labels: {labels}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 5 outputs of the forward pass on the test data\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "  for X_test, y_test in test_dataloader:\n",
    "    X_test, y_test = X_test.to(device), y_test.to(device)  # Move tensors to the same device as the model\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_0(X_test.to(device))[:5]\n",
    "y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sigmoid activation function on our model logits to turn them into prediction probabilities\n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the predicted labels\n",
    "y_preds = torch.round(y_pred_probs)\n",
    "\n",
    "# Convert the tensor to a list of labels\n",
    "y_pred_labels = [classes[int(label)] for label in y_preds]\n",
    "\n",
    "print(y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc = (correct/len(y_pred)) * 100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Creating a Training loop and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training time)\n",
    "epochs = 10\n",
    "\n",
    "# Create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n------\")\n",
    "\n",
    "  ### Training\n",
    "  train_loss, train_acc = 0, 0\n",
    "  batch_accuracy = 0\n",
    "\n",
    "  # Add a loop to loop through the training batches\n",
    "  for batch, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "    # Put data to target device\n",
    "    X, y = X.to(device), y.float().to(device)\n",
    "\n",
    "    model_0.train()\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X).squeeze()\n",
    "    #print(y_pred.type)\n",
    "    #print(y_pred[0])\n",
    "\n",
    "    # 2. Calculate loss (per batch)\n",
    "    loss = loss_fn(y_pred.view(-1), y.float())\n",
    "    train_loss += loss.item() # accumulate train loss\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step (update the model's parameters once *per batch*)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    y_pred_class = torch.round(torch.sigmoid(y_pred))\n",
    "    #print(y_pred_class)\n",
    "    #print(y_pred_class.view(-1))\n",
    "    batch_accuracy = (y_pred_class.view(-1) == y).sum().item() / len(y_pred_class)\n",
    "    #print(f\"Batch accuracy: {batch_accuracy}\")\n",
    "\n",
    "    # Accumulate the batch accuracy to the training accuracy\n",
    "    train_acc += batch_accuracy\n",
    "    #print(f\"Cumulative training accuracy: {train_acc}\")\n",
    "\n",
    "    # Print out what's happening\n",
    "    if batch % 400 == 0:\n",
    "        print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "\n",
    "  # Divide total train loss by length of train dataloader\n",
    "  train_loss /= len(train_dataloader)\n",
    "  train_acc /= len(train_dataloader)\n",
    "\n",
    "  print(f\"\\nTrain loss: {train_loss:.4f}\")\n",
    "  print(f\"Cumulative training accuracy: {train_acc}\")\n",
    "\n",
    "  ### Testing\n",
    "  test_loss, correct_predictions, total_predictions = 0, 0, 0\n",
    "  real_as_real, real_as_fake, fake_as_real, fake_as_fake = 0, 0, 0, 0\n",
    "  model_0.eval()\n",
    "  with torch.inference_mode():\n",
    "      for i, (X_test, y_test) in enumerate(test_dataloader):\n",
    "          # Put data to target device\n",
    "          X_test, y_test = X_test.to(device), y_test.float().to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred = model_0(X_test).squeeze()\n",
    "\n",
    "          # 2. Calculate loss (accumulatively)\n",
    "          test_loss += loss_fn(test_pred, y_test.float()).item()\n",
    "\n",
    "          # 3. Calculate accuracy\n",
    "          test_pred_class = torch.round(torch.sigmoid(test_pred))\n",
    "          correct_predictions += (test_pred_class.view(-1) == y_test).sum().item()\n",
    "          total_predictions += len(y_test)\n",
    "\n",
    "          # Print image names and predictions\n",
    "          for j in range(len(X_test)):\n",
    "              image_index = i * test_dataloader.batch_size + j\n",
    "              image_name = test_dataloader.dataset.data[image_index][0]\n",
    "              true_label = test_dataloader.dataset.data[image_index][1]\n",
    "              predicted_label = test_pred_class[j].item()\n",
    "              #print(f\"Image: {image_name}, True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
    "              #print(f\"Image: {image_name}, True Label: {classes[int(true_label)]}, Predicted Label: {classes[int(predicted_label)]}\")\n",
    "\n",
    "              if true_label == 0 and predicted_label == 0:\n",
    "                  real_as_real += 1\n",
    "              elif true_label == 0 and predicted_label == 1:\n",
    "                  real_as_fake += 1\n",
    "              elif true_label == 1 and predicted_label == 0:\n",
    "                  fake_as_real += 1\n",
    "              elif true_label == 1 and predicted_label == 1:\n",
    "                  fake_as_fake += 1\n",
    "              #print(real_as_real, real_as_fake, fake_as_real, fake_as_fake)\n",
    "\n",
    "      # Calculate the test loss average per batch\n",
    "      test_loss /= len(test_dataloader)\n",
    "\n",
    "      # Calculate the test accuracy\n",
    "      #test_acc = correct_predictions / total_predictions\n",
    "      test_acc = (real_as_real + fake_as_fake) / (real_as_real + real_as_fake + fake_as_real + fake_as_fake)\n",
    "      print(f\"Real images identified as real: {real_as_real}\")\n",
    "      print(f\"Real images identified as fake: {real_as_fake}\")\n",
    "      print(f\"Fake images identified as real: {fake_as_real}\")\n",
    "      print(f\"Fake images identified as fake: {fake_as_fake}\")\n",
    "      print(f\"\\nReal images Total: {real_as_real + real_as_fake} | Fake images Total: {fake_as_real + fake_as_fake}\")\n",
    "      print(f\"\\nTest loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
    "\n",
    "# Print out what's happening\n",
    "print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
