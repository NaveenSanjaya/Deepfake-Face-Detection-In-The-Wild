{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "0.20.1+cu124\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast  # Import GradScaler and autocast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check versions\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to real and fake image directories\n",
    "train_real_path = r\"D:\\Projects\\SP CUP Dataset\\train\\real\" # r is because of the backslash causing \\p \n",
    "train_fake_path = r\"D:\\Projects\\SP CUP Dataset\\train\\fake\" # to be interpreted as a special character\n",
    "train_path = r\"D:\\Projects\\SP CUP Dataset\\train\"\n",
    "\n",
    "test_real_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\real\"\n",
    "test_fake_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\fake\"\n",
    "test_path = r\"D:\\Projects\\SP CUP Dataset\\valid\"\n",
    "\n",
    "#Small Dataset\n",
    "#train_real_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\real\" # r is because of the backslash causing \\p \n",
    "#train_fake_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\fake\" # to be interpreted as a special character\n",
    "#test_real_path = r\"D:\\Projects\\SP CUP Dataset\\Small train\\real\"\n",
    "#test_fake_path = r\"D:\\Projects\\SP CUP Dataset\\Small train\\fake\"\n",
    "\n",
    "#Define the maximum number of samples per class\n",
    "TRAIN_MAX_SAMPLES_PER_CLASS = 50000  # Programmer-defined limit\n",
    "TEST_MAX_SAMPLES_PER_CLASS = 50000  # Programmer-defined limit\n",
    "\n",
    "BATCH_SIZE = 16 # Batch size for training\n",
    "#LR = 0.1 # Learning rate\n",
    "RANDOM_SEED = 42 # Seed for random number generator\n",
    "Visualize = False # Visualize the data\n",
    "\n",
    "#Define the classes\n",
    "classes = ['Fake', 'Real']\n",
    "Real_Index = 1\n",
    "Fake_Index = 0\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✔ 1 for real and 0 for fake since classes = ['fake', 'real']\n",
    "fileID <TAB> score where fileID is the id of the test file, and score is a numerical value -- a higher value for real images and lower value for fake images.(from documentation)\n",
    "\n",
    "✔ The train_dataloader is created with shuffle=True to shuffle the training data at the beginning of each epoch. (not implemented )\n",
    "\n",
    "✔ The test_dataloader is created with shuffle=False to keep the order of the test data consistent.\n",
    "\n",
    "✔Read efficientnet documentation and act accordingly\n",
    "\n",
    "Way to save the model using checkpoints.\n",
    "\n",
    "Way to get std and mean of the provided dataset\n",
    "\n",
    "Apply regularization (Model markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Balanced Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_total_filecount(real_path, fake_path):\n",
    "    print(f\"Number of real images: {len(os.listdir(real_path))}, \"\n",
    "          f\"Number of fake images: {len(os.listdir(fake_path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real images: 42690, Number of fake images: 219470\n",
      "Number of real images: 1548, Number of fake images: 1524\n"
     ]
    }
   ],
   "source": [
    "display_total_filecount(train_real_path, train_fake_path)\n",
    "display_total_filecount(test_real_path, test_fake_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Create Balanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 100000 (Real: 50000, Fake: 50000)\n"
     ]
    }
   ],
   "source": [
    "#random.seed(RANDOM_SEED)\n",
    "\n",
    "#Get the image filenames\n",
    "train_real_images = os.listdir(train_real_path)\n",
    "train_fake_images = os.listdir(train_fake_path)\n",
    "\n",
    "# Apply the limit\n",
    "train_real_images = train_real_images[:min(TRAIN_MAX_SAMPLES_PER_CLASS, len(train_real_images))]\n",
    "#train_fake_images = train_fake_images[:min(TRAIN_MAX_SAMPLES_PER_CLASS, len(train_fake_images))]\n",
    "#Added Choosing random to avoid training only for a sample of the 200000 images\n",
    "train_fake_images = random.sample(train_fake_images, min(TRAIN_MAX_SAMPLES_PER_CLASS, len(train_fake_images)))\n",
    "\n",
    "# Oversample real_images to match the number of fake_images\n",
    "if len(train_real_images) < len(train_fake_images):\n",
    "    train_real_images = random.choices(train_real_images, k=len(train_fake_images))\n",
    "    \n",
    "# Combine and label the dataset\n",
    "train_balanced_dataset = [(os.path.join(train_real_path, img), Real_Index) for img in train_real_images] + \\\n",
    "                   [(os.path.join(train_fake_path, img), Fake_Index) for img in train_fake_images]\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(train_balanced_dataset)\n",
    "\n",
    "# Verify the limited dataset size\n",
    "print(f\"Total dataset size: {len(train_balanced_dataset)} (Real: {len(train_real_images)}, Fake: {len(train_fake_images)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 3072 (Real: 1548, Fake: 1524)\n"
     ]
    }
   ],
   "source": [
    "# Get the image filenames\n",
    "test_real_images = os.listdir(test_real_path)\n",
    "test_fake_images = os.listdir(test_fake_path)\n",
    "\n",
    "# Apply the limit\n",
    "test_real_images = test_real_images[:min(TEST_MAX_SAMPLES_PER_CLASS, len(test_real_images))]\n",
    "test_fake_images = test_fake_images[:min(TEST_MAX_SAMPLES_PER_CLASS, len(test_fake_images))]\n",
    "\n",
    "# Combine and label the dataset\n",
    "test_balanced_dataset = [(os.path.join(test_real_path, img), Real_Index) for img in test_real_images] + \\\n",
    "                   [(os.path.join(test_fake_path, img), Fake_Index) for img in test_fake_images]\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(test_balanced_dataset)\n",
    "\n",
    "# Verify the limited dataset size\n",
    "print(f\"Total dataset size: {len(test_balanced_dataset)} (Real: {len(test_real_images)}, Fake: {len(test_fake_images)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Visualize balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images(dataset, num_images):\n",
    "    # Set the random seed for reproducibility\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # Randomly select num_images from the dataset\n",
    "    selected_indices = random.sample(range(len(dataset)), num_images)\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 8))  # Adjust the figsize as needed\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        image_path, label = dataset[idx]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Display the image\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Label: {'Real' if label == Real_Index else 'Fake'}\")\n",
    "        axes[i].set_xlabel(os.path.basename(image_path))  # Display the image name\n",
    "        axes[i].axis('off')  # Hide the axis\n",
    "        \n",
    "        # Print the image file name and shape\n",
    "        print(f\"Image file name: {os.path.basename(image_path)}\")\n",
    "        print(f\"Image Shape: {image.size}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with train_balanced_dataset and a seed value\n",
    "if Visualize==True:\n",
    "    display_random_images(train_balanced_dataset, num_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Transformed Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Image Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        super().__init__()  # Call the parent class's init method\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Finding out mean and std to use in the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_and_std_from_dataset(dataset, device='cuda'):\n",
    "    \"\"\"\n",
    "    Compute per-channel mean and std of the dataset (to be used in transforms.Normalize())\n",
    "    Args:\n",
    "        dataset (list): List of tuples containing image paths and labels.\n",
    "        device (str): Device to perform computations on ('cuda' or 'cpu').\n",
    "    Returns:\n",
    "        mean (list): List of mean values for each channel.\n",
    "        std (list): List of standard deviation values for each channel.\n",
    "    \"\"\"\n",
    "    # Initialize variables to store the sum and sum of squares of pixel values\n",
    "    mean = torch.zeros(3).to(device)\n",
    "    std = torch.zeros(3).to(device)\n",
    "    num_images = len(dataset)\n",
    "    \n",
    "    for img_path, _ in tqdm(dataset, desc=\"Computing mean and std\"):\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image).to(device)\n",
    "        \n",
    "        mean += image.mean(dim=(1, 2))\n",
    "        std += image.std(dim=(1, 2))\n",
    "    \n",
    "    mean /= num_images\n",
    "    std /= num_images\n",
    "\n",
    "    mean = [round(m.item(), 4) for m in mean]\n",
    "    std = [round(s.item(), 4) for s in std]\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "#train_mean, train_std = compute_mean_and_std_from_dataset(train_balanced_dataset)\n",
    "#print(f\"Train Mean: {train_mean}, Train Std: {train_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_mean, test_std = compute_mean_and_std_from_dataset(test_balanced_dataset)\n",
    "#print(f\"Test Mean: {test_mean}, Test Std: {test_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Create transformed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label: 0, Class name: Fake\n"
     ]
    }
   ],
   "source": [
    "train_mean, train_std = [0.4598, 0.3929, 0.3792], [0.2327, 0.2046, 0.2103]\n",
    "test_mean, test_std = [0.3996, 0.3194, 0.3223], [0.2272, 0.1706, 0.1718]\n",
    "\n",
    "#train_mean, train_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "#test_mean, test_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "#This transform has better accuracy than the one below\n",
    "# Define transforms\n",
    "#transform = transforms.Compose([\n",
    "#    Resize((224, 224)),\n",
    "#    ToTensor(),\n",
    "#    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),  # First resize to 256\n",
    "    #transforms.CenterCrop(224),  # Then center crop to 224\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip image horizontally with 50% probability\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=train_mean.tolist(), std=train_std.tolist())\n",
    "\n",
    "    #transforms.ColorJitter(\n",
    "    #                brightness=0.2,      # Random brightness adjustment\n",
    "    #                contrast=0.2,        # Random contrast adjustment\n",
    "    #                saturation=0.2,      # Random saturation adjustment\n",
    "    #                hue=0.1             # Random hue adjustment\n",
    "    #            ),\n",
    "\n",
    "    transforms.Normalize(mean=train_mean, std=train_std)\n",
    "\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),  # First resize to 256\n",
    "    #transforms.CenterCrop(224),  # Then center crop to 224\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=test_mean.tolist(), std=test_std.tolist())\n",
    "    transforms.Normalize(mean=test_mean, std=test_std)\n",
    "])\n",
    "\n",
    "#Create the dataset\n",
    "train_data = ImageDataset(train_balanced_dataset, \n",
    "                          transform=train_transform)\n",
    "\n",
    "#Create the dataset\n",
    "test_data = ImageDataset(test_balanced_dataset, \n",
    "                        transform=test_transform)\n",
    "\n",
    "# Example: Print the class name of a label\n",
    "for image, label in test_data:\n",
    "    class_name = classes[label]\n",
    "    print(f\"Image label: {label}, Class name: {class_name}\")\n",
    "    break  # Just print the first one for demonstration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Visualize transformed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Unnormalize a tensor image.\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The normalized tensor image.\n",
    "        mean (torch.Tensor): The mean used for normalization.\n",
    "        std (torch.Tensor): The standard deviation used for normalization.\n",
    "    Returns:\n",
    "        torch.Tensor: The unnormalized tensor image.\n",
    "    \"\"\"\n",
    "    tensor = tensor.clone()  # Clone the tensor to avoid modifying the original\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)  # Unnormalize\n",
    "    return tensor\n",
    "\n",
    "def plot_random_images(dataset, transform, num_images):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # Randomly select num_images from the dataset\n",
    "    selected_indices = random.sample(range(len(dataset)), num_images)\n",
    "    \n",
    "    # Display num_images before and after transform\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(20, 8))  # 2 rows, num_images columns\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        image_path, label = dataset[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Display original image\n",
    "        axes[0, i].imshow(image)\n",
    "        axes[0, i].set_title(f\"Original\\nLabel: {'Real' if label == Real_Index else 'Fake'}\")\n",
    "        axes[0, i].axis('off')  # Hide the axis\n",
    "\n",
    "        # Apply transform and display transformed image\n",
    "        transformed_image = transform(image)\n",
    "        axes[1, i].imshow(transformed_image.permute(1, 2, 0))  # Display the transformed image\n",
    "        axes[1, i].set_title(f\"Transformed\\nLabel: {'Real' if label == Real_Index else 'Fake'}\")\n",
    "        axes[1, i].axis('off')  # Hide the axis\n",
    "\n",
    "        # Unnormalize and display the unnormalized image\n",
    "        unnormalized_image = unnormalize(transformed_image, train_mean, train_std)\n",
    "        axes[2, i].imshow(unnormalized_image.permute(1, 2, 0))  # Unnormalize the image\n",
    "        axes[2, i].set_title(f\"Unnormalized\\nLabel: {'Real' if label == Real_Index else 'Fake'}\")\n",
    "        axes[2, i].axis('off')  # Hide the axis\n",
    "\n",
    "        # Print the transformed image shape and label\n",
    "        print(transformed_image.shape, label)\n",
    "        print(f\"Image file name: {image_path}\")\n",
    "        print(f\"Image label: {[label]}\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with train_balanced_dataset and train_transform\n",
    "if Visualize==True:\n",
    "    plot_random_images(train_balanced_dataset, train_transform, num_images=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(train_data, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_data, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Visualize DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224]) torch.Size([16])\n",
      "torch.Size([3, 224, 224])\n",
      "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000234E4EFE090>, <torch.utils.data.dataloader.DataLoader object at 0x00000234E52872F0>)\n",
      "Length of train_dataloader: 6250 batches of 16... = 100000\n",
      "Length of test_dataloader: 192 batches of 16... = 3072\n"
     ]
    }
   ],
   "source": [
    "# Example: Iterate through the DataLoader\n",
    "for images, labels in test_dataloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break\n",
    "\n",
    "print(images[0].shape)\n",
    "\n",
    "\n",
    "# Let's check out what what we've created\n",
    "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}... = {BATCH_SIZE*len(train_dataloader)}\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}... = {BATCH_SIZE*len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Building a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.0 Model_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained EfficientNet model\n",
    "class DeepFakeDetectV0(nn.Module):\n",
    "    def __init__(self, output_shape: int):\n",
    "        super(DeepFakeDetectV0, self).__init__()\n",
    "        # Load pre-trained EfficientNet model\n",
    "        self.efficientnet = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Unfreeze more layers\n",
    "        for param in self.efficientnet.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(num_ftrs, output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Setup the model for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_0 = DeepFakeDetectV0(output_shape=1)\n",
    "model_0.to(device)\n",
    "\n",
    "# Check the device of the model\n",
    "model_0_device = next(model_0.parameters()).device\n",
    "print(f\"Model is on device: {model_0_device}\")\n",
    "#model_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Visualize Model's Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Visualize == True:\n",
    "    # Test with random tensor (batch_size=32, channels=3, height=224, width=224)\n",
    "    test_input = torch.randn(32, 3, 224, 224).to(device)\n",
    "    output = model_0(test_input)\n",
    "    print(f\"Input shape: {test_input.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Sample predictions:\\n{output[:5].cpu().detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Check the State Dictionary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Visualize == True:\n",
    "    print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Further Checking the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Visualize == True:\n",
    "    # Iterate through the test_dataloader and print the first 5 values\n",
    "    for i, (images, labels) in enumerate(test_dataloader):\n",
    "        if i < 1:\n",
    "            print(f\"Batch {i+1}:\")\n",
    "            print(f\"Images: {images}\")\n",
    "            print(f\"Labels: {labels}\")\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Visualize == True:\n",
    "    # View the first 5 outputs of the forward pass on the test data\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "      for X_test, y_test in test_dataloader:\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)  # Move tensors to the same device as the model\n",
    "        # 1. Forward pass\n",
    "        y_logits = model_0(X_test.to(device))[:5]\n",
    "        break\n",
    "      \n",
    "    print(\"y_logits \",y_logits)\n",
    "    print(\"y_test \", y_test[:5])\n",
    "\n",
    "    # Use the sigmoid activation function on our model logits to turn them into prediction probabilities\n",
    "    y_pred_probs = torch.sigmoid(y_logits)\n",
    "    print(\"y_pred_probs \",y_pred_probs)\n",
    "    # Find the predicted labels\n",
    "    y_preds = torch.round(y_pred_probs)\n",
    "\n",
    "    # Convert the tensor to a list of labels\n",
    "    y_pred_labels = [classes[int(label)] for label in y_preds]\n",
    "\n",
    "    print(y_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Setup Loss, Optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 Setup Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function and optimizer\n",
    "#loss_fn = nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            #lr=0.01)\n",
    "# Define the optimizer\n",
    "#optimizer = optim.Adam(model_0.parameters(), lr=LR)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "#scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#Define optimizer with initial learning rate\n",
    "initial_lr = 0.003  # EfficientNet often works well with lower learning rates\n",
    "optimizer = optim.Adam(model_0.parameters(), lr=initial_lr)\n",
    "\n",
    "# Create scheduler with OneCycleLR - works well for deepfake detection\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=initial_lr,  \n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    pct_start=0.3,      # Warm up for 30% of training\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10,      # initial_lr/10 will be used as starting lr\n",
    "    final_div_factor=100  # final lr will be initial_lr/1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 Function to time our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu: 0.000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.320000046689529e-05"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "  \"\"\"Prints difference between start and end time.\"\"\"\n",
    "  total_time = end - start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time\n",
    "\n",
    "start_time = timer()\n",
    "# some code...\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.3 Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc = (correct/len(y_pred)) * 100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GradScaler for mixed precision training\n",
    "scaler = torch.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_948\\1629135735.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_save_path))\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "model_save_path = f\"deepfake_detect_model_20250112_164232.pth\"\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = DeepFakeDetectV0(output_shape=1)\n",
    "loaded_model.load_state_dict(torch.load(model_save_path))\n",
    "loaded_model.to(device)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "model_0 = loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Creating a Training loop and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4ae4e706ea4ab0a9337660dcd7d949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e848879af1314bc1b0684c884e1e6011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/100000 samples.\n",
      "Looked at 6400/100000 samples.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 4. Loss backward\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 5. Optimizer step (update the model's parameters once *per batch*)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "random.seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training time)\n",
    "epochs = num_epochs\n",
    "\n",
    "# Create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n------\")\n",
    "\n",
    "  ### Training\n",
    "  train_loss, train_acc = 0, 0\n",
    "  batch_accuracy = 0\n",
    "\n",
    "  # Add a loop to loop through the training batches\n",
    "  for batch, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "    # Put data to target device\n",
    "    X, y = X.to(device), y.float().to(device)\n",
    "\n",
    "    model_0.train()\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X).squeeze()\n",
    "    #print(y_pred.type)\n",
    "    #print(y_pred[0])\n",
    "\n",
    "    # 2. Calculate loss (per batch)\n",
    "    loss = loss_fn(y_pred.view(-1), y.float())\n",
    "    train_loss += loss.item() # accumulate train loss\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step (update the model's parameters once *per batch*)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    y_pred_class = torch.round(torch.sigmoid(y_pred))\n",
    "    #print(y_pred_class)\n",
    "    #print(y_pred_class.view(-1))\n",
    "    batch_accuracy = (y_pred_class.view(-1) == y).sum().item() / len(y_pred_class)\n",
    "    #print(f\"Batch accuracy: {batch_accuracy}\")\n",
    "\n",
    "    # Accumulate the batch accuracy to the training accuracy\n",
    "    train_acc += batch_accuracy\n",
    "    #print(f\"Cumulative training accuracy: {train_acc}\")\n",
    "\n",
    "    # Print out what's happening\n",
    "    if batch % 400 == 0:\n",
    "        print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "\n",
    "    scheduler.step()  # Update learning rate at each step\n",
    "\n",
    "  # Divide total train loss by length of train dataloader\n",
    "  train_loss /= len(train_dataloader)\n",
    "  train_acc /= len(train_dataloader)\n",
    "\n",
    "  print(f\"\\nTrain loss: {train_loss:.4f}\")\n",
    "  print(f\"Cumulative training accuracy: {train_acc}\")\n",
    "\n",
    "  # Add at the end of each epoch in the training loop\n",
    "  current_lr = optimizer.param_groups[0]['lr']\n",
    "  print(f\"Epoch {epoch} ending learning rate: {current_lr:.6f}\")\n",
    "\n",
    "\n",
    "  ### Testing\n",
    "  test_loss, correct_predictions, total_predictions = 0, 0, 0\n",
    "  real_as_real, real_as_fake, fake_as_real, fake_as_fake = 0, 0, 0, 0\n",
    "  model_0.eval()\n",
    "  with torch.inference_mode():\n",
    "      for i, (X_test, y_test) in enumerate(test_dataloader):\n",
    "          # Put data to target device\n",
    "          X_test, y_test = X_test.to(device), y_test.float().to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred = model_0(X_test).squeeze()\n",
    "\n",
    "          # 2. Calculate loss (accumulatively)\n",
    "          test_loss += loss_fn(test_pred, y_test.float()).item()\n",
    "\n",
    "          # 3. Calculate accuracy\n",
    "          test_pred_class = torch.round(torch.sigmoid(test_pred))\n",
    "          correct_predictions += (test_pred_class.view(-1) == y_test).sum().item()\n",
    "          total_predictions += len(y_test)\n",
    "\n",
    "          # Print image names and predictions\n",
    "          for j in range(len(X_test)):\n",
    "              image_index = i * test_dataloader.batch_size + j\n",
    "              image_name = test_dataloader.dataset.data[image_index][0]\n",
    "              true_label = test_dataloader.dataset.data[image_index][1]\n",
    "              predicted_label = test_pred_class[j].item()\n",
    "              #print(f\"Image: {image_name}, True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
    "              #print(f\"Image: {image_name}, True Label: {classes[int(true_label)]}, Predicted Label: {classes[int(predicted_label)]}\")\n",
    "\n",
    "              if true_label == 0 and predicted_label == 0:\n",
    "                  real_as_real += 1\n",
    "              elif true_label == 0 and predicted_label == 1:\n",
    "                  real_as_fake += 1\n",
    "              elif true_label == 1 and predicted_label == 0:\n",
    "                  fake_as_real += 1\n",
    "              elif true_label == 1 and predicted_label == 1:\n",
    "                  fake_as_fake += 1\n",
    "              #print(real_as_real, real_as_fake, fake_as_real, fake_as_fake)\n",
    "\n",
    "      # Calculate the test loss average per batch\n",
    "      test_loss /= len(test_dataloader)\n",
    "\n",
    "      # Calculate the test accuracy\n",
    "      #test_acc = correct_predictions / total_predictions\n",
    "      test_acc = (real_as_real + fake_as_fake) / (real_as_real + real_as_fake + fake_as_real + fake_as_fake)\n",
    "      print(f\"Real images identified as real: {real_as_real}\")\n",
    "      print(f\"Real images identified as fake: {real_as_fake}\")\n",
    "      print(f\"Fake images identified as real: {fake_as_real}\")\n",
    "      print(f\"Fake images identified as fake: {fake_as_fake}\")\n",
    "      print(f\"\\nReal images Total: {real_as_real + real_as_fake} | Fake images Total: {fake_as_real + fake_as_fake}\")\n",
    "      print(f\"\\nTest loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  model_save_path = f\"deepfake_detect_model_{timestamp}.pth\"\n",
    "  torch.save(model_0.state_dict(), model_save_path)\n",
    "  print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "  # Print out what's happening\n",
    "  print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc*100:.4f}% | Test loss: {test_loss:.4f} | Test acc: {test_acc*100:.4f}%\")\n",
    "\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime import datetime\n",
    "#model_save_path = f\"deepfake_detect_model_20250110_201404.pth\"\n",
    "\n",
    "# Load the trained model\n",
    "#loaded_model = DeepFakeDetectV0(output_shape=1)\n",
    "#loaded_model.load_state_dict(torch.load(model_save_path))\n",
    "#loaded_model.to(device)\n",
    "#print(\"Model loaded successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7488\\1629135735.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "model_save_path = f\"deepfake_detect_model_20250112_164232.pth\"\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = DeepFakeDetectV0(output_shape=1)\n",
    "loaded_model.load_state_dict(torch.load(model_save_path))\n",
    "loaded_model.to(device)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "model_0 = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real images identified as real: 1261\n",
      "Real images identified as fake: 287\n",
      "Fake images identified as real: 457\n",
      "Fake images identified as fake: 1067\n",
      "\n",
      "Real images Total: 1548 | Fake images Total: 1524\n",
      "\n",
      "Test loss: 0.5485, Test acc: 0.7578\n",
      "Test loss: 0.5485, Test acc: 0.7578\n"
     ]
    }
   ],
   "source": [
    "### Testing\n",
    "test_loss, correct_predictions, total_predictions = 0, 0, 0\n",
    "real_as_real, real_as_fake, fake_as_real, fake_as_fake = 0, 0, 0, 0\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    for i, (X_test, y_test) in enumerate(test_dataloader):\n",
    "        # Put data to target device\n",
    "        X_test, y_test = X_test.to(device), y_test.float().to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        test_pred = model_0(X_test).squeeze()\n",
    "\n",
    "        # 2. Calculate loss (accumulatively)\n",
    "        test_loss += loss_fn(test_pred, y_test.float()).item()\n",
    "\n",
    "        # 3. Calculate accuracy\n",
    "        test_pred_class = torch.round(torch.sigmoid(test_pred))\n",
    "        correct_predictions += (test_pred_class.view(-1) == y_test).sum().item()\n",
    "        total_predictions += len(y_test)\n",
    "\n",
    "        # Print image names and predictions\n",
    "        for j in range(len(X_test)):\n",
    "            image_index = i * test_dataloader.batch_size + j\n",
    "            image_name = test_dataloader.dataset.data[image_index][0]\n",
    "            true_label = test_dataloader.dataset.data[image_index][1]\n",
    "            predicted_label = test_pred_class[j].item()\n",
    "            #print(f\"Image: {image_name}, True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
    "            #print(f\"Image: {image_name}, True Label: {classes[int(true_label)]}, Predicted Label: {classes[int(predicted_label)]}\")\n",
    "\n",
    "            if true_label == 1 and predicted_label == 1:\n",
    "                real_as_real += 1\n",
    "            elif true_label == 1 and predicted_label == 0:\n",
    "                real_as_fake += 1\n",
    "            elif true_label == 0 and predicted_label == 1:\n",
    "                fake_as_real += 1\n",
    "            elif true_label == 0 and predicted_label == 0:\n",
    "                fake_as_fake += 1\n",
    "            #print(real_as_real, real_as_fake, fake_as_real, fake_as_fake)\n",
    "\n",
    "    # Calculate the test loss average per batch\n",
    "    test_loss /= len(test_dataloader)\n",
    "\n",
    "    # Calculate the test accuracy\n",
    "    #test_acc = correct_predictions / total_predictions\n",
    "    test_acc = (real_as_real + fake_as_fake) / (real_as_real + real_as_fake + fake_as_real + fake_as_fake)\n",
    "    print(f\"Real images identified as real: {real_as_real}\")\n",
    "    print(f\"Real images identified as fake: {real_as_fake}\")\n",
    "    print(f\"Fake images identified as real: {fake_as_real}\")\n",
    "    print(f\"Fake images identified as fake: {fake_as_fake}\")\n",
    "    print(f\"\\nReal images Total: {real_as_real + real_as_fake} | Fake images Total: {fake_as_real + fake_as_fake}\")\n",
    "    print(f\"\\nTest loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
    "\n",
    "# Print out what's happening\n",
    "print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
