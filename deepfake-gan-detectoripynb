{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnV54gYkWMfF4Usxr3Kncf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaveenSanjaya/Deepfake-Face-Detection-In-The-Wild/blob/main/deepfake-gan-detectoripynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL7y0Y0ndnUg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Custom Dataset class for handling multiple deepfake datasets\n",
        "class MultiSourceDeepfakeDataset(Dataset):\n",
        "    def __init__(self, root_dirs, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dirs (dict): Dictionary containing paths to different datasets\n",
        "            transform: Image transformations to be applied\n",
        "        \"\"\"\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Process each dataset\n",
        "        for dataset_name, dataset_path in root_dirs.items():\n",
        "            real_path = os.path.join(dataset_path, 'real')\n",
        "            fake_path = os.path.join(dataset_path, 'fake')\n",
        "\n",
        "            # Add real images\n",
        "            for img_name in os.listdir(real_path):\n",
        "                self.image_paths.append(os.path.join(real_path, img_name))\n",
        "                self.labels.append(1)  # 1 for real\n",
        "\n",
        "            # Add fake images\n",
        "            for img_name in os.listdir(fake_path):\n",
        "                self.image_paths.append(os.path.join(fake_path, img_name))\n",
        "                self.labels.append(0)  # 0 for fake\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Generator Network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, channels=3):\n",
        "        \"\"\"\n",
        "        Generator network that creates synthetic images\n",
        "        Args:\n",
        "            latent_dim: Size of the input noise vector\n",
        "            channels: Number of output image channels (3 for RGB)\n",
        "        \"\"\"\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial dense layer to reshape noise\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 4 * 4)\n",
        "\n",
        "        # Transposed convolution layers\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.deconv4 = nn.ConvTranspose2d(64, channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        # Batch normalization layers\n",
        "        self.bn1 = nn.BatchNorm2d(256)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input noise\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 512, 4, 4)\n",
        "\n",
        "        # Apply transposed convolutions with batch normalization and ReLU\n",
        "        x = F.relu(self.bn1(self.deconv1(x)))\n",
        "        x = F.relu(self.bn2(self.deconv2(x)))\n",
        "        x = F.relu(self.bn3(self.deconv3(x)))\n",
        "\n",
        "        # Final layer with tanh activation\n",
        "        x = torch.tanh(self.deconv4(x))\n",
        "        return x\n",
        "\n",
        "# Discriminator Network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels=3):\n",
        "        \"\"\"\n",
        "        Discriminator network that classifies images as real or fake\n",
        "        Args:\n",
        "            channels: Number of input image channels (3 for RGB)\n",
        "        \"\"\"\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(channels, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        # Batch normalization layers\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "        self.bn2 = nn.BatchNorm2d(256)\n",
        "        self.bn3 = nn.BatchNorm2d(512)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.fc = nn.Linear(512 * 4 * 4, 1)\n",
        "\n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply convolutions with leaky ReLU and batch normalization\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        x = F.leaky_relu(self.bn1(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.bn2(self.conv3(x)), 0.2)\n",
        "        x = F.leaky_relu(self.bn3(self.conv4(x)), 0.2)\n",
        "\n",
        "        # Flatten and apply dropout\n",
        "        x = x.view(-1, 512 * 4 * 4)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Final classification\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x\n",
        "\n",
        "# Training function\n",
        "def train_gan(generator, discriminator, dataloader, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Training loop for the GAN\n",
        "    Args:\n",
        "        generator: Generator network\n",
        "        discriminator: Discriminator network\n",
        "        dataloader: DataLoader containing the training data\n",
        "        num_epochs: Number of training epochs\n",
        "        device: Device to train on (CPU/GPU)\n",
        "    \"\"\"\n",
        "    # Loss function and optimizers\n",
        "    criterion = nn.BCELoss()\n",
        "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (real_images, _) in enumerate(dataloader):\n",
        "            batch_size = real_images.size(0)\n",
        "\n",
        "            # Create labels\n",
        "            real_labels = torch.ones(batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "            # Train Discriminator\n",
        "            real_images = real_images.to(device)\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            # Loss on real images\n",
        "            d_output_real = discriminator(real_images)\n",
        "            d_loss_real = criterion(d_output_real, real_labels)\n",
        "\n",
        "            # Loss on fake images\n",
        "            noise = torch.randn(batch_size, 100).to(device)\n",
        "            fake_images = generator(noise)\n",
        "            d_output_fake = discriminator(fake_images.detach())\n",
        "            d_loss_fake = criterion(d_output_fake, fake_labels)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # Train Generator\n",
        "            g_optimizer.zero_grad()\n",
        "            g_output = discriminator(fake_images)\n",
        "            g_loss = criterion(g_output, real_labels)\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], '\n",
        "                      f'd_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Define dataset paths\n",
        "    dataset_paths = {\n",
        "        'celeb_df_v1': 'path/to/celeb_df_v1',\n",
        "        'celeb_df_v2': 'path/to/celeb_df_v2',\n",
        "        'faceforensics': 'path/to/faceforensics',\n",
        "        'dfdc': 'path/to/dfdc'\n",
        "    }\n",
        "\n",
        "    # Define transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = MultiSourceDeepfakeDataset(dataset_paths, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "    # Initialize networks\n",
        "    generator = Generator().to(device)\n",
        "    discriminator = Discriminator().to(device)\n",
        "\n",
        "    # Train the model\n",
        "    train_gan(generator, discriminator, dataloader, num_epochs=100, device=device)\n",
        "\n",
        "    # Save the trained models\n",
        "    torch.save(generator.state_dict(), 'generator.pth')\n",
        "    torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}